{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598cd49d-f49c-4b2d-8227-00648f8c27c1",
   "metadata": {},
   "source": [
    "# POTATO Take-Home Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc601b6-b2ec-4ad8-8fe3-1e0d74a9ca9a",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook processes Twitter data from TSV files, allowing for various queries based on user input.\n",
    "\n",
    "## Part 1: Data Ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54a9e7-d17a-45c7-89dc-f6e8ccf64894",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbd31ca-b401-4b3f-baab-a7b374003ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\toshiba\\appdata\\roaming\\python\\python311\\site-packages (2.2.2)\n",
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.15.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: flask in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.15.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
      "   ---------------------------------------- 0.0/524.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/524.6 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/524.6 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/524.6 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/524.6 kB ? eta -:--:--\n",
      "   -------------------------------------- 524.6/524.6 kB 494.3 kB/s eta 0:00:00\n",
      "Downloading elastic_transport-8.15.0-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.15.0 elasticsearch-8.15.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas elasticsearch flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267ed5a5-93e9-4e8a-b946-d608e48c3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7394ae-c22e-4c08-871f-c2eb6d03c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "tweets_df = pd.read_csv('correct_twitter_201904.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc9365e-ce5f-4e7d-b264-384c2c2407e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>from_stream</th>\n",
       "      <th>directly_from_stream</th>\n",
       "      <th>from_search</th>\n",
       "      <th>directly_from_search</th>\n",
       "      <th>from_quote_search</th>\n",
       "      <th>directly_from_quote_search</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_author_id</th>\n",
       "      <th>retweeted_handle</th>\n",
       "      <th>retweeted_follower_count</th>\n",
       "      <th>mentioned_author_ids</th>\n",
       "      <th>mentioned_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>media_keys</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131594960443199488</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131594976750653440</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1131589737955942405</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131594909469892610</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1131594812694511617</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           event                               ts1  \\\n",
       "0  1131594960443199488  britney_201904  2022-02-28 09:34:44.627023-05:00   \n",
       "1  1131594976750653440  britney_201904  2022-02-28 09:34:44.626921-05:00   \n",
       "2  1131589737955942405  britney_201904  2022-02-28 09:34:44.634058-05:00   \n",
       "3  1131594909469892610  britney_201904  2022-02-28 09:34:44.627125-05:00   \n",
       "4  1131594812694511617  britney_201904  2022-02-28 09:34:44.627227-05:00   \n",
       "\n",
       "                                ts2  from_stream  directly_from_stream  \\\n",
       "0  2022-02-28 09:34:44.627023-05:00         True                  True   \n",
       "1  2022-02-28 09:34:44.626921-05:00         True                  True   \n",
       "2  2022-02-28 09:34:44.634058-05:00         True                  True   \n",
       "3  2022-02-28 09:34:44.627125-05:00         True                  True   \n",
       "4  2022-02-28 09:34:44.627227-05:00         True                  True   \n",
       "\n",
       "   from_search  directly_from_search  from_quote_search  \\\n",
       "0        False                 False              False   \n",
       "1        False                 False              False   \n",
       "2        False                 False              False   \n",
       "3        False                 False              False   \n",
       "4        False                 False              False   \n",
       "\n",
       "   directly_from_quote_search  ...     retweeted  retweeted_author_id  \\\n",
       "0                       False  ...  1.130918e+18         3.042894e+09   \n",
       "1                       False  ...           NaN                  NaN   \n",
       "2                       False  ...           NaN                  NaN   \n",
       "3                       False  ...  1.130918e+18         3.042894e+09   \n",
       "4                       False  ...  1.130918e+18         3.042894e+09   \n",
       "\n",
       "   retweeted_handle  retweeted_follower_count mentioned_author_ids  \\\n",
       "0          Iesbwian                   22760.0                  NaN   \n",
       "1               NaN                       NaN                  NaN   \n",
       "2               NaN                       NaN                  NaN   \n",
       "3          Iesbwian                   22760.0                  NaN   \n",
       "4          Iesbwian                   22760.0                  NaN   \n",
       "\n",
       "  mentioned_handles  hashtags urls media_keys  place_id  \n",
       "0               NaN       NaN  NaN        NaN       NaN  \n",
       "1               NaN       NaN  NaN        NaN       NaN  \n",
       "2               NaN       NaN  NaN        NaN       NaN  \n",
       "3               NaN       NaN  NaN        NaN       NaN  \n",
       "4               NaN       NaN  NaN        NaN       NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f27576bf-828e-431a-af44-251e5ac75870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch client with host specification\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "# Ingest data into Elasticsearch\n",
    "def ingest_data(df):\n",
    "    for index, row in df.iterrows():\n",
    "        es.index(index='tweets', body=row.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48eacb05-6170-428f-b99a-00f4046df8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets_by_day(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"tweets_per_day\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"created_at\",\n",
    "                    \"interval\": \"day\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['tweets_per_day']['buckets']\n",
    "\n",
    "def count_unique_users(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"unique_users\": {\n",
    "                \"cardinality\": {\n",
    "                    \"field\": \"user_id\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['unique_users']['value']\n",
    "\n",
    "def average_likes(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"average_likes\": {\n",
    "                \"avg\": {\n",
    "                    \"field\": \"likes\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['average_likes']['value']\n",
    "\n",
    "def tweets_by_place(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"places\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"place_id\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['places']['buckets']\n",
    "\n",
    "def tweets_by_time_of_day(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"time_of_day\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"created_at\",\n",
    "                    \"interval\": \"hour\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['time_of_day']['buckets']\n",
    "\n",
    "def top_user(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"top_users\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"user_id\",\n",
    "                    \"size\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['top_users']['buckets'][0] if response['aggregations']['top_users']['buckets'] else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f87b7f3c-1eb3-43d2-b741-c40e71fae5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "if not es.ping():\n",
    "    print(\"Connection failed\")\n",
    "else:\n",
    "    print(\"Connection successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bea1b8c-dea6-48aa-8115-500b4fa487d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5a4051-547d-45c5-b79a-efc9644f777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed9552f3-cd25-43d6-8494-f17bed7c15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query error: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x000001FDDB14B990>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it))\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "# Function to count tweets by day\n",
    "def count_tweets_by_day(term):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": term\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"tweets_per_day\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"created_at\",\n",
    "                    \"calendar_interval\": \"day\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index='tweets', body=query)\n",
    "    return response['aggregations']['tweets_per_day']['buckets']\n",
    "\n",
    "# Example search term\n",
    "search_term = \"music\"\n",
    "\n",
    "# Execute the query\n",
    "try:\n",
    "    print(\"Tweets per day:\", count_tweets_by_day(search_term))\n",
    "except Exception as e:\n",
    "    print(f\"Query error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b6d74d-4c57-4e94-8ac8-17050523604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "try:\n",
    "    if es.ping():\n",
    "        print(\"Connection successful\")\n",
    "    else:\n",
    "        print(\"Connection failed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Elasticsearch: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2c10c-7af2-4a3d-b3f8-c1c3a85ef973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
